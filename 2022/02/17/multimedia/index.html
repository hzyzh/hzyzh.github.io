<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hzyzh.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Intro  目标  多媒体技术在计算机上的表示（怎样表示一个视频、声音、图形） 掌握多媒体编码标准 当前的多媒体处理技术和相关算法  什么是媒体  媒体（Media）：发布信息，表现信息的手段、方法、工具、设备或装置  两种形式：  感觉媒体：人——人 或 人——机交换信息的形式（可以通过视觉、听觉 感知到） 表示媒体：计算机内部或机——机交换信息的形式（二进制编">
<meta property="og:type" content="article">
<meta property="og:title" content="multimedia">
<meta property="og:url" content="https://hzyzh.github.io/2022/02/17/multimedia/index.html">
<meta property="og:site_name" content="Eden">
<meta property="og:description" content="Intro  目标  多媒体技术在计算机上的表示（怎样表示一个视频、声音、图形） 掌握多媒体编码标准 当前的多媒体处理技术和相关算法  什么是媒体  媒体（Media）：发布信息，表现信息的手段、方法、工具、设备或装置  两种形式：  感觉媒体：人——人 或 人——机交换信息的形式（可以通过视觉、听觉 感知到） 表示媒体：计算机内部或机——机交换信息的形式（二进制编">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="f:/blog/source_posts/figs/fig3.png">
<meta property="og:image" content="f:/blog/source_posts/figs/equation1.png">
<meta property="og:image" content="f:/blog/source_posts/figs/fig20.png">
<meta property="og:image" content="f:/blog/source_posts/figs/fig34.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig35.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig49.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig41.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig42.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig43.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig50.jpg">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig51.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig52.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig53.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig54.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig55.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig56.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig57.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig58.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig59.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig60.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig61.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig70.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig71.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig72.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig73.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig74.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig62.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig63.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig64.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig65.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig66.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig67.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig68.png">
<meta property="og:image" content="f:/blog/source/_posts/figs/fig69.png">
<meta property="article:published_time" content="2022-02-17T02:40:49.000Z">
<meta property="article:modified_time" content="2023-01-24T08:13:52.837Z">
<meta property="article:author" content="Zeyu Huang">
<meta property="article:tag" content="CS">
<meta property="article:tag" content="Lecture notes">
<meta property="article:tag" content="Multimedia">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="f:/blog/source_posts/figs/fig3.png">

<link rel="canonical" href="https://hzyzh.github.io/2022/02/17/multimedia/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>multimedia | Eden</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Eden</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://hzyzh.github.io/2022/02/17/multimedia/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zeyu Huang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          multimedia
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-02-17 10:40:49" itemprop="dateCreated datePublished" datetime="2022-02-17T10:40:49+08:00">2022-02-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-01-24 16:13:52" itemprop="dateModified" datetime="2023-01-24T16:13:52+08:00">2023-01-24</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="intro">Intro</h2>
<ul>
<li><p>目标</p>
<ul>
<li><p>多媒体技术在计算机上的表示（怎样表示一个视频、声音、图形）</p></li>
<li><p>掌握多媒体编码标准</p></li>
<li><p>当前的多媒体处理技术和相关算法</p></li>
</ul></li>
<li><p>什么是媒体</p>
<ul>
<li>媒体（Media）：发布信息，表现信息的手段、方法、工具、设备或装置
<ul>
<li>两种形式：
<ul>
<li>感觉媒体：人——人 或 人——机交换信息的形式（可以通过视觉、听觉
感知到）</li>
<li>表示媒体：计算机内部或机——机交换信息的形式（二进制编码形式存储）：称为数字媒体形式</li>
</ul></li>
<li>感觉媒体和表示媒体的转换（输入设备、输出设备），是主要研究部分！</li>
<li>按生成属性分类
<ul>
<li>自然媒体：客观世界存在的。。。经过特定设备，进行数字化和编码处理后得到的
<strong>数字媒体</strong> （如：Digital video，Bitmap image）</li>
<li>合成媒体：以计算机为工具、采用特定符号、语言、算法表示等，由计算机生成（合成）的文本、音乐、动画等等
（如MIDI？graphics，computer animation）</li>
<li>两者区别：
<ul>
<li>1.客观世界存在否；</li>
<li>2.表示方式：
<ul>
<li>自然媒体：离散样本方式；</li>
<li>合成媒体：由符号、语言、算法 所表示的</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>啥是多媒体？ any combination of text, graphic art, sound, animation,
video delivered by computers</li>
<li>多媒体技术：可以大大提高人机交互效率（各种人机交互接口）</li>
</ul></li>
<li><p>多媒体技术的研究内容</p>
<ul>
<li>各种媒体输入 <span class="math inline">\(\to\)</span>
媒体的表示（编码） <span class="math inline">\(\to\)</span>
媒体的编辑（对媒体信息的一些修改？） <span
class="math inline">\(\to\)</span>
媒体的集成（多种媒体的同步、集成等等） <span
class="math inline">\(\to\)</span> 媒体传输（一般是网络） <span
class="math inline">\(\to\)</span> 媒体消费（*要把表示媒体 转换为
感觉媒体！）</li>
</ul>
<ol type="1">
<li>媒体的输入
<ul>
<li>自然媒体：通过捕获 &amp; 数字化（自然界中真实存在）
<ul>
<li>将物理量、化学量、生物量等转换成<strong>电信号</strong>（如麦克风把声波
从 机械信号 转换成 电信号）</li>
<li>然后通过采样、量化、编码等处理，将<strong>模拟电信号</strong> 转成
特定格式的数据文件</li>
</ul></li>
<li>合成媒体：通过建模（通过专门的算法、语言、脚本来描述）
<ul>
<li>创建：先建模，得到
采用特定符号（语言）或某种算法表示的媒体（如编码文本、MIDI音乐、计算机动画、Graphics。。。）</li>
<li><strong>渲染</strong>：最后展示的时候，要转换为
感觉媒体（离散的样本点）
<ul>
<li>渲染 就是将合成媒体，转换为离散样本</li>
</ul></li>
</ul></li>
</ul></li>
<li>媒体的表示
<ul>
<li>文本编码</li>
<li>声音编码</li>
<li>图像编码
<ul>
<li>多分辨：一个图像可以支持多分辨率，即根据当前场景的复杂程度，选择不同分辨率</li>
</ul></li>
<li>视频编码
<ul>
<li>（以上三个都：）压缩问题 和 传输问题</li>
<li>可伸缩性：一套码流
支持多种分辨率（标清：只解析标清码流；高清：同时也解析高清码流。。。）</li>
</ul></li>
<li>编码标准：
<ul>
<li>音频：MPEG</li>
<li>图像：bmp，gif，<strong>JPEG</strong></li>
<li>视频：H系列（要求编码解码实时性），MPEG系列（不要求编码，但要求解码实时性）</li>
</ul></li>
</ul></li>
<li>媒体的编辑（editing）
<ul>
<li>内容增删改；变换、效果处理；布局安排；类型转换（自然形式（媒体）的取样表示
<span class="math inline">\(\to\)</span> 符号化 <span
class="math inline">\(\to\)</span> <strong>符号表示</strong>）</li>
</ul></li>
<li>媒体的传输
<ul>
<li>网络传输</li>
<li>载体发布：CD、DVD、HD DVD、蓝光Disk</li>
</ul></li>
<li>媒体的消费
<ul>
<li>文本：浏览、阅读</li>
<li>图像：渲染</li>
<li>等等</li>
</ul></li>
</ol></li>
<li><p>多媒体技术的发展</p>
<ul>
<li>网络化</li>
</ul></li>
</ul>
<h2 id="文本编码">文本编码</h2>
<ul>
<li><p>ASCII码：7位二进制编码；96个可打印字符+32个控制字符</p>
<ul>
<li>一般ASCII码为：ISO-646-US标准；也有其他本地化版本（ISO-646-）</li>
</ul></li>
<li><p>扩充ASCII码（ISO-8859）：8位二进制编码（低位兼容ASCII（0+7位）；高位从0xA1开始定义，分为若干不同的字符集）</p></li>
<li><p>汉字编码：GB2312-1980：（简体中文字符集，+ASCII码等西文字符）</p>
<ul>
<li>区位码（8bit）+基类码（8bit）（94个区+94个位）</li>
<li>存储时，为了和ASCII码区分，<strong>将区位码 和
基类码都加上A0</strong>（单字节的最高位置为1）</li>
</ul></li>
<li><p>GB12345-1990：</p>
<ul>
<li>繁体汉字编码（专门用来编码繁体的）</li>
</ul></li>
<li><p>CJK（中日韩）</p></li>
<li><p>GBK（GB2312 + CJK + ...）</p>
<ul>
<li>双字节编码，第一字节最高位必为1，第2字节最高位不一定！（仍能和单字节的ASCII码兼容）</li>
<li>与GB2312-80向下兼容</li>
</ul></li>
<li><p>UCS：将所有字符统一在一个字符集中（留了00 0000 0000 到10 ffff
ffff的编码空间）</p>
<ul>
<li>UCS的变形显示形式之一UTF-8（可变长形式编码）
<ul>
<li><img src="F:\blog\source_posts\figs\fig3.png" title="fig:"
alt="img" /></li>
</ul></li>
<li>UTF-16：两个字节一起来读入（允许插入一些4字节的UCS-4字符）：
<ul>
<li>读入两个字节：如果在D800到DFFF之间，则表示是四个字节的字符，否则两个字节</li>
<li>UTF-16能表示UCS中的全部字符</li>
</ul></li>
</ul></li>
</ul>
<h2 id="数字图像基础">数字图像基础</h2>
<ul>
<li><p>颜色模型</p>
<ul>
<li>颜色三要素：
<ul>
<li>色调：颜色的外观，决定于光的波长</li>
<li>饱和度：纯度/彩度（彩色中含白光的量）</li>
<li>亮度：强度，能量</li>
</ul></li>
<li>颜色模型：
<ul>
<li>加色模型RGB；减色模型CMY(K黑)</li>
</ul></li>
<li>抖动：
<ul>
<li>用空间换效果</li>
</ul></li>
<li>八叉树颜色量化算法！</li>
</ul></li>
<li><p>图像与图形</p>
<ul>
<li>图像（Image）
<ul>
<li>取样图（点位图）：图像的空间离散化</li>
</ul></li>
<li>图形（graphics）
<ul>
<li>矢量图：通过计算机指令表示</li>
</ul></li>
</ul></li>
<li><p>数字取样图像的表示</p>
<ul>
<li>分辨率（屏幕、图像 分辨率）</li>
<li>像素深度（存储每个像素所用的位数）</li>
<li>调色板（颜色查找表，只需存储索引）</li>
</ul></li>
<li><p>常用图像文件的格式</p>
<ul>
<li>bmp：windows通用的图像文件格式
<ul>
<li>包含：文件头，信息头，调色板，位图数据</li>
<li>位图数据：扫描行是由底向上存储的，这就是说，阵列中的第一个字节表示位图左下角的像素，而最后一个字节表示位图右上角的像素。
一行的字节数必须为4的倍数。</li>
</ul></li>
<li>gif：颜色少（不超过256），特别小；图像中可加入文本</li>
<li>png</li>
</ul></li>
<li><p>合成图像（与数字取样图像相对）的创建与表示</p>
<ul>
<li><p>合成图像：使用算法或几何要素以及材料性质，来描述形体；显示时，会根据观察者位置以及光线来生成景物</p></li>
<li><p>建模方法：</p>
<ul>
<li><p>几何造型技术：线框模型、表面模型、实体模型</p>
<ul>
<li><p>线框模型：点和棱边，没有面，不能表示含曲面物体</p></li>
<li><p>表面模型：面的集合表示物体，环界定面的边界；但不能计算体积、表面积等</p></li>
<li><p>Bezier样条曲线函数：有<span class="math inline">\(p_0,
p_1,\cdots, p_n\)</span>n+1个点，以此模拟出一条曲线：（除<span
class="math inline">\(p_0,p_n\)</span>外，其他点都仅提供方向信息，一般不经过）</p>
<p><img src="F:\blog\source_posts\figs\equation1.png" /></p></li>
<li><p>实体模型</p></li>
</ul></li>
<li><p>过程造型</p>
<ul>
<li>分形几何：初始图形的每一点，不断重复使用给定的变换函数（固定的或随机的）
<ul>
<li>如：三角形（初始元）+每边突出一个角（生成元generator）</li>
<li>统计自相似分形几何构造：重在随机性（如模拟叶脉）</li>
</ul></li>
<li>L系统</li>
<li>粒子系统</li>
<li>基于物理的建模</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>数字图像的展现</p>
<p>展现：将取样/合成图像从内部表示转换为在图像输出设备上可见的视图</p>
<p>​ 包括：reconstruction：取样图像 展现到输出设备；rendering：合成图像
展现到输出设备（比较复杂，计算量很大）</p>
<ul>
<li>CRT显示器：阴极射线（控制信号
控制电压大小），同时只有一束电流！（不断一行一行发射）</li>
<li>液晶显示器：通过改变光的振动方向，来控制显示强度（有一个配光板，只有某一方向震动的光能通过）</li>
<li>显示控制卡（or图形卡、视频卡、图形加速卡、视频适配卡，显卡）
<ul>
<li>包括：显示存储器（VRAM），GPU，绘图与显示控制电路</li>
<li>VRAM：存储正在显示的图像数据（双缓存：还存储下一帧要显示的内容）；以及作为GPU的内存！</li>
<li>GPU：以及将RGB数字信号转换为模拟信号</li>
<li>绘图与显示控制电路：对CRT或液晶显示器进行控制，与CPU一起完成图像生成与更新。</li>
</ul></li>
<li>GPU（graphic processing unit）：
<ul>
<li>主要为了大量的、并行的数据计算：<strong>渲染！</strong>（rgb<span
class="math inline">\(\to\)</span>模拟信号）</li>
<li>NVIDIA的GPU：CUDA核心（通用GPU核心！可以像在CPU上编程一样在GPU上编程，也可以图像渲染）；Tensor核心：专为张量和矩阵计算（深度学习）</li>
</ul></li>
<li>图像绘制过程：
<ul>
<li>光线跟踪方法（ray tracing）
<ul>
<li>正向效果：光源处发出无数光线，在到达表面上反射、折射，直到部分光到达投影平面（/反射、折射一定次数）</li>
<li>逆向效果：以像素为起点</li>
<li>添加阴影（通过光源+建模和算法计算得到）、表面细节、纹理、材质</li>
</ul></li>
<li>方式：点绘制、面绘制、体绘制</li>
<li>rendering pipeline：（OpenGL）
<ul>
<li>需要定义：光源，观察点（视点），成像面，距离，大小。。。</li>
<li>景物的模型<span
class="math inline">\(\to\)</span>取景变换（坐标变换）<span
class="math inline">\(\to\)</span>视域裁剪（快速判断哪些物体在视域内）<span
class="math inline">\(\to\)</span>三角化（把所有景物转化为三角网格mesh）<span
class="math inline">\(\to\)</span>光栅化<span
class="math inline">\(\star\)</span>（关键步骤，所有可视对象转化为像素！一般通过光线追踪实现）<span
class="math inline">\(\to\)</span>隐藏面消除（保留最靠前的对象像素，还要考虑透明效果、折射反射效果）<span
class="math inline">\(\to\)</span>明暗处理<span
class="math inline">\(\to\)</span>阴影生成<span
class="math inline">\(\to\)</span>纹理映射<span
class="math inline">\(\to\)</span>最终景物的像 （此即rendering
pipeline全过程）</li>
</ul></li>
<li>纹理：用一些算法，将真是的照片蒙在mesh上，不影响几何形状；几何纹理：对几何形状也会产生一定扰动（如一个高尔夫球）</li>
</ul></li>
<li>合成图像的展现</li>
</ul></li>
</ul>
<h2 id="数字视频">数字视频</h2>
<ul>
<li><p>模拟视频：随时间变化其内容的一组图像（n帧/秒），又叫运动图像</p>
<ul>
<li>彩色电视图像摄取、传输和重现的过程：拍摄和播放都采用
<strong>光栅扫描</strong> 方法（依次扫描成像平面每一像素）</li>
<li>彩电信号传输：用Y（亮度）、C1、C2（色差信号，与彩电制式相关，比如我国用PAL制式、美国用NTSC制式）</li>
<li>显示：光栅扫描（<strong>逐行扫描</strong>；也有
隔行扫描interlaced（奇数场+偶数场$$1帧图像），<strong>隔行扫描</strong>
转化到逐行扫描 可能会造成模糊）</li>
<li>视频信号：
<ul>
<li>空间特性：需要有时间回扫（行回扫、列回扫）；一般宽高比为4：3或16：9</li>
<li>时间特性：动作连贯要求 帧频&gt;15f/s；无闪烁要求&gt;50f/s
<ul>
<li>PAL：每秒50场（隔行扫描）；NTSC：每秒60场。计算最（亮度信号）高频率时：全屏光点总数<span
class="math inline">\(\times\)</span>每秒帧数（场数除以二）<strong>/2</strong>（因为两个像素构成一个周期）</li>
<li>载波频率：PAL：8MHz；NTSC：6MHz</li>
</ul></li>
<li>电视信号的彩色空间：Y（亮度信号）,C1,C2（色差信号），根据RGB转换
<ul>
<li>为啥要用？：因为彩色电视信号 与 黑白电视兼容；利于压缩信号带宽</li>
</ul></li>
<li>视频信号种类：
<ul>
<li>复合电视信号：将 亮度、色度信号 以及同步信号
复合成单一信号。适合远距离传输（只需要单信道）</li>
</ul></li>
<li>接口种类：梯形的 HDMI高清信号；宽体型（15根信道）VGA</li>
</ul></li>
</ul></li>
<li><p>数字视频：易于编辑、修改、存储、传输，图像质量更好</p>
<ul>
<li><p>视频信号数字化：模拟视频信号输入：Y、U、V（模拟视频信号是连续的，时间和幅值上都是）</p>
<ul>
<li><p>1.滤波（过滤掉噪声）；2.取样（时间轴上（和x轴y轴？）离散），亮度信号采样频率13.5MHz；3.量化（值还是连续的，用8-10bit表示一个信号）；4.PCM编码（1.协议：如何解释这些比特流；2.压缩：数据量过大）=&gt;数字Y、U、V信号</p></li>
<li><p>取样：Y分量：标清水平分辨率720（一行
有720个像素可见）；垂直分辨率：PAL：576行可见；NTSC：480行可见（因为JPEG编码，需要按16×16的块）</p>
<p>U、V/I、Q：人眼对其不如Y信号敏感，因此不用每个采样点都有</p>
<p><img src="F:\blog\source_posts\figs\fig20.png" /></p></li>
</ul></li>
<li><p>数字视频的计时：00;02;51;20（小时；分钟；秒；帧）</p>
<ul>
<li>失落帧编码：00;02;51;20（分号），用于处理NTSC的实际频率为29.97fps：每一分钟的00秒，没有00和01帧；每十分钟的00秒，有00和01帧（类似闰年）</li>
<li>非失落帧编码：00:02:51:20（冒号）</li>
</ul></li>
</ul></li>
<li><p>计算机合成视频</p>
<ul>
<li>计算机动画：采用计算机合成，可供<strong>实时</strong>演播的一系列画面
的技术（是合成数字视频）</li>
<li>运动控制
<ul>
<li>类别：刚体运动：一些关键部件组成，不变形，仅相互位置关系变化；变形体运动：不仅相互位置变化，而且也变形</li>
<li>运动控制的方法：
<ul>
<li>关键帧人工给出几个关键帧的位置、形状、方向等等；中间帧靠计算机自动合成</li>
<li>计算法：（抽象成物理、数学模型）动力学（受力、加速度。。。）、随机方法（火焰、云彩、瀑布等，需要添加一些随机方法）、行为规则</li>
<li>运动捕获：现实的运动图像捕获（记录许多样本点的运动）（如人脸的表情）</li>
<li>重用以前的动作</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="声音">声音</h2>
<h4 id="声音的数字化">声音的数字化</h4>
<ul>
<li>声音：
<ul>
<li>物理特性：频率（音调，音高）；强度/振幅（音量）；波形（音色）</li>
<li>次声：0-20Hz；可听声：20-20kHz；超声：20kHz-
<ul>
<li>可听声中，分 语音（300-3400Hz） 和 全频带声音（20-20kHz）</li>
</ul></li>
<li>声谱图/频谱表示：在某一帧（时间点），各个频率的音波的振幅</li>
</ul></li>
<li>声音信号的数字化：
<ul>
<li>模拟声音信号（机械波） —&gt;
取样：（模拟的电信号，时间上离散，值上连续）声音不失真，采样频率至少要为信号最高频率的2倍（语音信号，采样频率一般就8kHz；CD则是44.1kHz（可听声最高20kHz））</li>
<li>—&gt; 量化：在取样值上也进行离散（量化精度）</li>
</ul></li>
<li>数字波形声音的基本参数
<ul>
<li>取样频率（每秒呈现多少个样本）；量化位数（决定了还原的质量）；声道数目（单/双）；压缩编码方法（压缩倍数）；比特率/码率（每秒钟的数据量，由前四个参数计算得到：1x2x3/4）</li>
<li>信噪比（SNR）：（评估一段信号的质量）<img
src="F:\blog\source_posts\figs\fig31.png" />
<ul>
<li>单位是分贝</li>
</ul></li>
<li>信号量化噪声比（QSNR）：量化之后 可表示的振幅数，和舍入误差比<img
src="F:\blog\source_posts\figs\fig32.png" /></li>
</ul></li>
<li>非均匀量化：量化间隔
不等；为了适合人耳听觉（低幅值区分明显，高幅值区分不明显）
<ul>
<li>对原样本先做一次μ/A律压扩算法，再对得到的样本进行线性量化取样（<strong>最后输出还要转回去吗？</strong>）</li>
</ul></li>
</ul>
<h4 id="合成语音">合成语音</h4>
<ul>
<li>语音基础知识：
<ul>
<li>音素：元音（浊音）；辅音（浊音或清音）
<ul>
<li>浊音声带振动；清音声带不振动。对于语音合成，浊音和清音合成方式不同！</li>
</ul></li>
</ul></li>
<li>文语转换：
<ul>
<li>文本—&gt; 分析：（发音规则库）通过编码查发音（辅音
元音），发音标注；（韵律规则库）韵律分析：根据各种，得到韵律控制参数</li>
<li>合成语音：从发音，得到波形；然后对波形进行一定修饰
<ul>
<li>两种方法：参数合成；波形拼接</li>
</ul></li>
</ul></li>
<li>参数合成法：把人的发声抽象为 激励信号，经过滤波器，得到一段波形
<ul>
<li>每个字（的语音），都通过一系列参数合成得到，包括激励信号、滤波器信号等等？</li>
<li>音素库小，需要的bit少（只需存那些参数）；但音质差</li>
</ul></li>
<li>波形拼接：记录一个人的字词发音，记录下波形在波形基元库中，最后进行一定修饰
<ul>
<li>语音基元波形库（预先存储大量语音基元（字或词）波形，合成时按字/词读取基元波形）</li>
<li>波形拼接+韵律修饰</li>
</ul></li>
</ul>
<h4 id="合成音乐">合成音乐</h4>
<ul>
<li><p>基本概念：</p>
<ul>
<li>用乐谱描述，由不同乐器演奏</li>
<li>音符：音调，音色，音强，持续时间</li>
</ul></li>
<li><p>波表合成器：类似与语音合成的波形拼接？</p>
<ul>
<li>存储各乐器的各音符的数字化波形于波表</li>
<li>播放的时候修饰成需要的音强和时长</li>
</ul></li>
<li><p>MIDI（Musical Digital Interface）：</p>
<ul>
<li><p>记录乐谱，而非波形信号</p></li>
<li><p>输入设备：根据人们的演奏，通过MIDI接口传输给音序器</p></li>
<li><p>音序器：组织好音色、节奏、音符等等音序信息，让音源发声（MIDI文件）</p></li>
<li><p>音源：里有合成器，有且仅有16个channel，MIDI文件中的各个音轨（track）必须要映射到其中一个channel；每一时刻，一个channel只能演奏一种音色！但可以多个乐谱（4把小提琴同channel）；总共支持128种音色</p></li>
<li><p>优点：数据量小，易于制作和编辑修改（只需要改乐谱）</p></li>
<li><p>缺点：表现力不行，音质与硬件相关</p></li>
</ul></li>
</ul>
<h2 id="压缩算法">压缩算法</h2>
<h4 id="无损压缩算法">无损压缩算法</h4>
<ul>
<li><p>基本概念</p>
<ul>
<li>图像数据压缩的可能性：
<ul>
<li>时间、空间冗余；信息熵冗余（可变长编码，给出现多的短编码（问求提到过））；等等</li>
<li>信息熵η➗平均码长L，越大（接近1）越好<img
src="F:\blog\source_posts\figs\fig33.png" /></li>
</ul></li>
<li>数据压缩的性能指标：
<ul>
<li>压缩比：压缩倍数，压缩效率，bits per pixel（bpp）</li>
<li>算法复杂度</li>
<li>重建质量：
<ul>
<li>客观法：均方误差；信噪比等（见ppt7：p7）</li>
<li>主观法：虽然受评价者本身影响，但在应用方面更加准确有效</li>
</ul></li>
</ul></li>
<li>压缩编码技术大概思想：
<ul>
<li>统计（熵）编码：统计符号出现概率，给出现概率高的符号短码字</li>
<li>预测编码：（图像/视频/音频数据
时间/空间冗余）已知像素（块）预测相邻/下一帧 像素（块）；
<ul>
<li>对差值编码，减少编码位数</li>
</ul></li>
<li>变换编码：对图像进行空间上的正交变换
<ul>
<li>比如一个正弦波，与其记录其每一时刻的波形，也许可以变换到另一维度（数学公式？），只需记录其频率，振幅</li>
<li>傅里叶变换；还可以通过机器学习</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>行程长度编码（run length code：RLC）</p>
<ul>
<li>对于连续出现同一数据序列如55555000111，表示为：553031</li>
<li>二值序列：00001110000001101111：436214（甚至不需要记录数值）</li>
</ul></li>
<li><p>变长度编码</p>
<ul>
<li><p>Shannon-Fano编码：</p>
<ol type="1">
<li>统计每个符号出现概率</li>
<li>从大到小排列</li>
<li>每个集合切分，按最接近50%切</li>
<li>对每个集合重复3，直到其中只包括一个符号</li>
</ol></li>
<li><p>Huffman编码：</p>
<ol type="1">
<li>统计+排序</li>
<li>最小的两个合并，并加入队列，排序</li>
<li>重复2，构建出Huffman树</li>
<li>为树上<strong>每条边</strong>分配一个编码，统一概率大者分配0，概率小者分配1</li>
</ol>
<ul>
<li><p>编码方式可能不唯一：（编码效率都相同）但可能最长码长不同，倾向于选最长码长较短的</p>
<ul>
<li>方法就是：每次插入的时候，如果出现相等的概率，则新插入的排前面（即优先合并已有的）</li>
</ul></li>
<li><p>传输中 误码影响较大！（一旦出错，
可能后面解码全部错误）；需要先统计符号出现分布；每次需要重新计算码表</p></li>
<li><p>自适应Huffman（例如针对ASCII码字符的）：传输过程中不断去调整Huffman树；但每一时刻，编码确定</p>
<ul>
<li>首次出现的字符，编码为前缀pre+其ASCII码编码</li>
<li>然后将该字符插入树中，编码为pre+1</li>
<li>pre变为pre+0</li>
<li>当树不平衡时（任何一颗子树中，左子节点权重大于右子节点权重），需要进行子树的切换（此次输入之前，同权重的两个节点对应的子树进行交换（一定是和根节点更近/靠右的），且优先和<strong>拓扑距离最远</strong>的节点交换！）这是为了保证编码
和 解码处的Huffman树是唯一确定的</li>
</ul></li>
</ul></li>
<li><p>字典编码：（LZW编码）</p>
<ul>
<li>思想：给信号源中的各符号序列
编码（建立编码表）；当下次再出现时，直接用编码即可；一般编码的码长为12bit</li>
<li>编码过程：读入符号，直到出现未见过的符号序列S+c，将S的编码输出，并为S+c编码，c作为下个S的开端；<strong>初始时，符号表中有确定的单个符号编码，编解码处应当相同！</strong></li>
<li>解码过程：初始符号表中有同编码表中一样的每个单个符号的编码；读入编码，并将对应的符号串输出以及压入buffer，buffer中同时只有两个符号串；将buffer中上个符号串S1+当前符号串<strong>S2[1]</strong>
作为新的一个符号串编码写入符号表！剔除S1，继续读入</li>
<li>解码有一个问题：当刚刚新编码的符号串
立马就使用的时候，就就会出现解码过程中不知道该读入什么符号串，此时新编码的符号串一定就是当前buffer中的唯一符号串S+S[1]！将其压入buffer并继续即可</li>
<li>压缩效率不高</li>
</ul></li>
<li><p>算术编码：</p>
<ul>
<li>编码单位为一串符号；用[0,1)的一个半开子区间表示一个符号？符号之间不重合</li>
<li>算法：<img src="F:\blog\source_posts\figs\fig34.png" /></li>
<li>最后的编码为该区间内
bit最短的小数！（怎么找？一个一个bit构造和试）</li>
<li>缺点：区间表示的小数会越来越长，且区间再分时需要进行乘法运算，速度慢
<ul>
<li>解决方案：区间长度A用规格化形式表示，始终保持在0.75-1.5之间？；可以用移位代替乘法</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>预测编码</p>
<ul>
<li>差分编码：只需记录第一列像素信息+每个像素与左侧像素的差值，希望来降低编码所需bit
<ul>
<li>一般用在有损编码</li>
</ul></li>
<li>JPEG无损编码格式：
<ul>
<li>用相邻像素预测此像素信息，编码解码确定一个统一的公式：X=a1A+a2B+a3C；只需要记录预测
与
原像素的差值（需要的bit少）。其中A,B,C都是编码再解码后得到的像素信息</li>
</ul></li>
</ul></li>
</ul>
<h4 id="有损压缩算法">有损压缩算法</h4>
<p>首先需要评估信息损失的程度，以及对信息丢失的可容忍度</p>
<ul>
<li><p>变换编码</p>
<ul>
<li>编码：将数据通过变换T映射到另一个空间，使得信息主要集中在某几个维度，则丢掉/粗略处理其它不重要的维度</li>
<li>变换矩阵：变换方法是否固定？希望正交变换</li>
<li>解码：通过逆变换T'解码</li>
</ul></li>
<li><p>离散余弦变换（DCT）：</p>
<ul>
<li><p>对于x轴上可积的信号f（x），可以分解成若干不同频率的正/余弦（连续
傅里叶变换？），对于<strong>频率为u</strong>的正/余弦信号，其系数为F(u)（是系数！不是指振幅/强度哦！）</p>
<ul>
<li>本质就是，将原本是 时域上的函数<span
class="math inline">\(f(x)\)</span>， 变换为了频域上的函数<span
class="math inline">\(F(u)\)</span></li>
</ul></li>
<li><p>分解之后，高频部分的能量一般是较低的，可以忽略</p></li>
<li><p>离散傅里叶变换：（频率上不再是连续的，且去掉了虚数部分）见ppt8：p9；一般N最大取8<img src="F:\blog\source\_posts\figs\fig35.png" style="zoom:80%;" /></p>
<ul>
<li><span
class="math inline">\(\tilde{f}(i)\)</span>表示逆DCT，从变换后的值，再重现出原<span
class="math inline">\(f(i)\)</span></li>
</ul></li>
<li><p>有点像变换编码？只不过现在把n维的向量信息看作了一个n个采样点的波形图，对它进行离散傅里叶变换，分出的每个余弦波（F(0)是直流信号的系数），实际也是一维坐标</p></li>
<li><p>还有二维（2D）DCT变换：8x8，频率从左上到右下递减（频率：u[2,2] =
u[1,3] = u[3,1] = 1）：基函数就是二维的余弦函数呗</p>
<ul>
<li><img src="F:\blog\source\_posts\figs\fig49.png" style="zoom:80%;" /></li>
</ul></li>
<li><p>缺点：对脉冲信号不太行！且会对原图像进行分块压缩，则解压出的图像产生“方块”效应</p></li>
</ul></li>
<li><p>小波变换</p>
<ul>
<li><p>小波：</p>
<ul>
<li>一种函数：具有<strong>有限的持续时间</strong>、<strong>突变的频率和振幅</strong>
波形可以是<strong>不规则的/不对称的</strong>，在整个时间范围内的<strong>积分为0</strong>！
有好多种小波</li>
<li>首先 可以进行连续小波变换（CWT）：即将任意波形
分解为<strong>一段母小波</strong>的各种平移、缩放变换得到的小波的叠加；
<ul>
<li>由此，就有了
<strong>各种小波分解</strong>（Haar小波分解只是其中之一）</li>
</ul></li>
<li>接着有了 缩放 和 平移 均为2的j次幂的倍数 构造平方可积的实空间<span
class="math inline">\(L^2(R)\)</span>的规范正交基<img
src="F:\blog\source_posts\figs\fig40.png" /></li>
<li>平移和缩放：在同一频率上，通过平移来拟合波形的不同分段；然后再缩放，在新频率上再重复上步</li>
</ul></li>
<li><p>DWT：discrete wavelet transform</p>
<ul>
<li><p>做法：想想data mining？（1D）</p>
<ul>
<li><p>低通滤波器输出（保留信号中的低频成分，消除高频成分，得到模糊的信号）：原波形的两个数值的平均；</p></li>
<li><p>高通滤波器输出（消除低频成分，保留高频！）：前减后的差/2</p></li>
<li><p>分成若干Haar小波的系数<img src="F:\blog\source\_posts\figs\fig41.png" style="zoom:80%;" /></p></li>
<li><p>分析滤波器：高通+低通+下采样（否则会有冗余/重复）</p>
<ul>
<li>（5，3）整数滤波器：可以无损（无损和有损的统一！根据解码的程度来决定）
<ul>
<li>例如低通滤波器：<span class="math inline">\(h_0(n)=\)</span>(-1 2 6
2 -1)/8 0 +-1 +-2：表示计算第n个值时，应该：（6*cn + 2*cn-1 + 2*cn+1 +
-1*cn-2 + -1*cn+2) / 8</li>
<li>高通滤波器：<span class="math inline">\(h_1(n)=\)</span>(-1 2 -1)/2
0 -1
-2：同理，-1，-2表示前1、2个，从左到右一一对应；别忘了最后除2！</li>
</ul></li>
<li>（9，7）浮点滤波器：一定有损</li>
</ul></li>
<li><p>合成滤波器：上采样（先补0）+高通+低通+合成：注意顺序</p></li>
<li><p><strong>继续对低频信号，可以进行多级小波分解</strong>，也有同时还对高频信号分解的</p></li>
</ul></li>
<li><p>2D DWT：先对行进行低通+高通+下采样；然后对得到的 <strong>低频信号
</strong>和 <strong>高频信号</strong>
都分别对列进行低通+高通+下采样<img src="F:\blog\source\_posts\figs\fig42.png" style="zoom:80%;" /></p></li>
<li><p>DWT的优点：多分辨率；不会产生块状效应（与DCT相对）；可对脉冲信号分解；单一码流中可既无损又有损！</p></li>
</ul></li>
</ul></li>
<li><p>嵌入零树小波系数（EZW）</p>
<ul>
<li><p>比特平面编码：</p>
<ul>
<li>编码顺序为：按比特平面 从高到低，优先扔 <strong>最高频率的
最低有效位</strong>的比特</li>
</ul></li>
<li><p>零树结构：基于位平面编码（2-D DWT）</p>
<ul>
<li><p>父子结构：一次平面DWT中，低频信号
为外置位同位置的块的父亲</p></li>
<li><p>系数的分类：（4类，每种系数用2bit表示）</p>
<ul>
<li>零树根t：绝对值比阈值小，子子孙孙（绝对值？）都比阈值小</li>
<li>孤独零z：绝对值比阈值小，但子子孙孙中有（绝对值？）比阈值大的</li>
<li>正大系数p：有一个阈值，若比阈值大</li>
<li>负大系数n：绝对值比阈值大但为负？</li>
<li>用来确定 哪些位置上的值，在某些位置上是1</li>
</ul></li>
<li><p>逐次逼近量化（SAQ）</p>
<ul>
<li><p>用到两个表：主表，辅表</p></li>
<li><p>主扫描：</p>
<ol type="1">
<li>找到绝对值最大的系数n，阈值设为<span class="math inline">\(th=2^m
\leq n &lt; 2^{m + 1}\)</span></li>
<li>按块，从左到右，从上到下扫描，依次确定tzpn，写入主表</li>
<li>对于t，其所有子孙都不再扫描</li>
<li>将所有p和n对应的系数存入辅表（哪些系数在第m位为1）</li>
<li>将正/负大系数们原位置设为0</li>
</ol></li>
<li><p>辅扫描：</p>
<ol type="1">
<li>继续<strong>细分</strong>那些正/负大系数们的区间（通过新的阈值来划分区间）（存入辅表）</li>
</ol></li>
<li><p>循环主辅循环（阈值直到1，则为无损），上为编码过程<img src="F:\blog\source\_posts\figs\fig43.png" style="zoom:67%;" /></p></li>
<li><p>解码：</p>
<ul>
<li>（主）同样的顺序，对于t，就将它的所有子孙 都补出0来</li>
<li>（辅）根据辅表的1/0来对所有非零项进行细化更新</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<h2 id="jpeg图像压缩标准">JPEG（图像压缩标准）</h2>
<p>4种编码模式：1.无损编码（不常用）；2.基于DCT 的顺序编码； 3.基于DCT
的累进编码； 4.基于DCT 的层次编码</p>
<h4 id="jpeg图像压缩的主要步骤">JPEG图像压缩的主要步骤</h4>
<ul>
<li><p>基本流程：</p>
<ol type="1">
<li>RGB 转为 YIQ / YUV（亮度+色度分量，可以丢掉部分色度IQ/UV）</li>
<li>分块：分为8×8的块，对每一块进行2维DCT变换（离散余弦变换）</li>
<li>量化：（量化阶）如仅4bit，但要表示0~60：则设置量化阶位4，通过乘以量化阶来表示</li>
<li>分别对直流 和 交流信号 进行不同编码</li>
</ol></li>
<li><p><strong>预处理和 FDCT</strong>（傅里叶 离散余弦变换）：</p>
<ul>
<li>首先 将RGB颜色空间 转换为 YC<span
class="math inline">\(_r\)</span>C<span
class="math inline">\(_b\)</span>空间（YUV）；</li>
<li>然后分块，分成8×8的子块：（4：2：2的色度格式）<img src="F:\blog\source\_posts\figs\fig50.jpg" style="zoom:50%;" /></li>
<li>电平偏移：对每个像素的值进行电平偏移（方便表示）
<ul>
<li>原本像素值范围在[0, <span
class="math inline">\(2^P-1\)</span>]（P=8一般）；调整为范围：[<span
class="math inline">\(-2^{P-1}, 2^{P-1}-1\)</span>]</li>
</ul></li>
</ul></li>
<li><p><strong>DCT系数的量化</strong>：（直观理解：就是压缩！用少bit来表示大范围数据，但是每个bit之间跨度较大（量化阶））</p>
<ul>
<li>量化处理：量化后的DCT系数<span class="math inline">\(\hat{F}(u,v) =
round\Big(\frac{F(u,v)}{Q(u,v)}\Big)\)</span>
<ul>
<li>其中量化矩阵<span class="math inline">\(Q(u,v)=Q\times
V(u,v)\)</span>，Q为<strong>质量因子</strong>，V（u，v）为<strong>亮度/色度量化表</strong></li>
<li>如：<img src="F:\blog\source\_posts\figs\fig51.png" style="zoom:70%;" /></li>
<li>Q越小，CR越低，图像质量好（损失的信息少，但非零系数少，压缩文件大小
较大）</li>
<li>对于图像中
较为平缓的（变化不明显，DCT后高频信号基本为0的），量化处理前后
损失的信息很少，不明显；</li>
</ul></li>
</ul></li>
<li><p><strong>熵编码</strong>：（对<span
class="math inline">\(\hat{F}(u,v)\)</span>进行表示，不会丢失信息）</p>
<ul>
<li><p>直流系数DC<span class="math inline">\(_i\)</span>的处理
<strong>DPCM</strong>：作差分！（只需记录
与左侧相邻块的直流系数的差）</p>
<ul>
<li>一般而言，相邻块之间的DC系数不会差太大，但是理论最大差值需要10bits表示，因此采用<strong>变长编码</strong>方式</li>
<li>采用两个符号表示（SIZE, AMPLITUDE）：SIZE表示：该<span
class="math inline">\(d_i\)</span>所用的bit位数，SIZE固定4bit；AMPLITUDE
= $d_i <span class="math inline">\(= DC\)</span>_i$ - DC<span
class="math inline">\(_{i-1}\)</span>（<span
class="math inline">\(d_0\)</span>=DC<span
class="math inline">\(_0\)</span>），若为负，则用反码表示，如-6表示为001（110的反码）</li>
</ul></li>
<li><p>交流系数AC<span class="math inline">\(_i\)</span>，zigzag
拉成一个一维数组，<strong>RLC</strong>（run-length
code）：然后对这个一维数组序列 进行
<strong>行程长度编码</strong>（原本为：分别统计连续0和连续1的个数）</p>
<ul>
<li>如：<img src="F:\blog\source\_posts\figs\fig52.png" style="zoom:65%;" /></li>
<li>行程编码：连续<span
class="math inline">\(n_i\)</span>个0，下一个非零值为<span
class="math inline">\(p_i\)</span>。。。最后全零，就记录0，0
<ul>
<li>因为应用量化后，会出现很多0，所以用这种方式</li>
</ul></li>
<li>也采用两个符号表示：
<ul>
<li>symbol1：（RUNLENGTH, SIZE）：两者皆是 4bit定长；
<ul>
<li>RUNLENGTH：游程长度，0~15；</li>
<li>SIZE：同DPCM中的SIZE，表示AMPLITUDE（下一个遇到的非零系数）的位数</li>
<li>若有超过15个连续的0，则将该游程切分为多段，全0游程用特殊符号：‘F0’来表示，则不需要符号2；若符号1为‘00’，则表示当前子块已结束（后全是0），也不需要符号2</li>
</ul></li>
<li>symbol2：（AMPLITUDE）下一个遇到的非零系数</li>
</ul></li>
</ul></li>
<li><p>霍夫曼编码：最后的输出，还要对DC和AC系数的<strong>符号1</strong>
进行霍夫曼编码，符号2均不变</p>
<ul>
<li><p><img src="F:\blog\source\_posts\figs\fig53.png" style="zoom:80%;" /></p></li>
<li><p>上为 固定的Huffman码表；或者指明了码表，用自定义的也行</p></li>
</ul></li>
</ul></li>
</ul>
<h4 id="编码模式">编码模式</h4>
<ul>
<li>基于DCT的顺序模式：流程就如上所示；码流是从上到下，从左到右的一个个块；</li>
<li>DCT-based累进模式：码流不再是一个个完整块，而是可能是一个个系数
<ul>
<li>频谱选择法：先输出/解码出 所有直流系数；然后依次增加交流系数</li>
<li>连续逼近法：将所有DCT系数同时编码，最先编码MSB（most significant
bit）</li>
</ul></li>
<li>DCT-based层次模式：
<ul>
<li>即根据不同的分辨率层次，（提供）进行不同的程度的 压缩编码</li>
<li>算法流程：<img src="F:\blog\source\_posts\figs\fig54.png" style="zoom:80%;" /></li>
<li>除最低分辨率外，每一级都是对<strong>差值图像</strong>进行JPEG编码！</li>
<li>JPEG用的很少</li>
</ul></li>
</ul>
<p>JPEG的压缩比与图像质量：</p>
<ul>
<li>压缩比（CR）：CR是一个大于1的整数
<ul>
<li>CR = 原始图像数据量 / 压缩后图像数据量
<ul>
<li>压缩后图像像素比特数 = 原始比特数 / CR（记住这个关系！）</li>
</ul></li>
<li>压缩比的控制（Q因子）：
<ul>
<li>量化矩阵 Q[u,v] = （Q (/50?)）*V[u,v]</li>
<li>故：Q小，CR小，压缩图像大，质量好</li>
<li>Q大，CR大，压缩图像小，质量差</li>
</ul></li>
</ul></li>
</ul>
<h4 id="jpeg2000">JPEG2000</h4>
<p>需要自学。。。</p>
<h2 id="ch10.-视频压缩基础">Ch10. 视频压缩基础</h2>
<p>视频压缩编码的标准</p>
<ul>
<li>ITU-T标准：视频会议、可视电话（主要用于通讯，对实时性要求高）</li>
<li>ISO/IEC国际标准：MPEG系列，主要用于娱乐（对质量要求高，编码实时性无要求，但解码需要实时性！）</li>
<li>AVI，QuickTime，RealTime</li>
</ul>
<p>H.261：ITU-T制定的视频编码标准：最主要最重要的 ~</p>
<ul>
<li>只支持图像格式：CIF（352×288像素）和QCIF（176×144像素）</li>
</ul>
<p>H.263：</p>
<ul>
<li>支持的图像格式增多了</li>
</ul>
<p>视频数据压缩编码的依据：</p>
<ul>
<li>每一帧画面<strong>内部</strong> 信息有强相关性</li>
<li>相邻帧之间有高度相似性</li>
<li>运动可估测</li>
<li>可利用人眼的视觉特性</li>
</ul>
<h4 id="视频压缩的基本方法">视频压缩的基本方法</h4>
<p>空间域：通过JPEG压缩算法 去掉画面内的冗余信息</p>
<p>时间域：采用<strong>运动补偿</strong>算法来去掉画面间的冗余信息</p>
<p><strong>运动补偿</strong>：</p>
<ul>
<li>不要整张画面编码，而是对于每一块，从前一帧中
找一块最相似的块，编码这两块的差值</li>
</ul>
<ol type="1">
<li><p>首先
将<strong>要编码的帧</strong>画面划分为宏块（16×16，由4块JPEG块组成），以宏块为单位，找出两帧画面中相应宏块的位移关系——<strong>运动矢量</strong></p>
<ul>
<li><strong><span
class="math inline">\(\textcolor{red}{注意}\)</span></strong>：参考画面（即上一帧，以编码好的画面，以编码后再解码出来的画面为准！<strong>而不是原画面</strong>！）不需要划分为宏块；参考画面中的宏块可以在任意位置！</li>
</ul></li>
<li><p>运动矢量的估计：参考画面中搜索对应宏块</p>
<ul>
<li><p>范围：2p+1：即参考帧中，该宏块的水平 和
垂直位移i，j都必须在范围[-p, p]内</p></li>
<li><p>找到最佳匹配块，最佳匹配块 相对于
该宏块的偏移量，称<strong>运动矢量</strong>，保存在输出码流中；</p></li>
<li><p>只需编码 宏块与 最佳匹配块的差值</p></li>
<li><p>最佳匹配准则：”方差和“SSE最小 or
”绝对误差和“SAD最小（M：mean；S：sum）</p>
<ul>
<li>搜索精度：1 pel；（也有0.5 pel之类的）</li>
<li><img src="F:\blog\source\_posts\figs\fig55.png" style="zoom:80%;" /></li>
</ul></li>
<li><p>搜索方法：</p>
<ul>
<li><p>顺序搜索：2p+1 × 2p+1个位置，依次计算每个运动矢量
对应的MAD（or。。。）</p></li>
<li><p>对数搜索法：（每次计算中 +
周围8个点（初始步长为1/2p）；找最匹配的，然后缩小步长为一半）<img src="F:\blog\source\_posts\figs\fig56.png" style="zoom: 67%;" /></p></li>
<li><p>层次搜索：</p>
<ul>
<li>分为k层，第k层 会对宏块 和 搜索范围 进行<span
class="math inline">\(2^k\)</span>的下采样，然后找到最佳匹配；</li>
<li>若第k层的运动矢量估计值为<span class="math inline">\((u^k,
v^k)\)</span>，则k-1层将以<span
class="math inline">\((2u^k,2v^k)\)</span>为中心，在<strong>3×3的区域</strong>内搜索</li>
<li>直到找到第0层的最佳匹配块</li>
<li>这种方法
计算效率最高（<strong>可是为什么要乘3？</strong>：3是指每个像素比较
需要三个操作完成）</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h4 id="h.261">H.261</h4>
<p>将视频的每一帧划分为了2种：</p>
<ul>
<li>I帧（帧内帧
<strong>Intra</strong>-frame）：独立的，不需要作预测，直接按JPEG方法编码；必须要有I帧</li>
<li>P帧（帧间帧
<strong>Inter</strong>-frame）：作预测编码（运动补偿）</li>
</ul>
<p>H.261的量化：（与JPEG的区别）因为对实时性要求高，因此作了一定简化</p>
<ul>
<li>没有量化表：8×8个系数的量化阶 都相同（2*（1~31）之间的一个数）
<ul>
<li><strong>特例</strong>：I帧的量化阶 都是8</li>
</ul></li>
</ul>
<p><strong>H.261
Encoder：</strong>（4：2：0，因此一个宏块包含4个Y块，1个Cb块，1个Cr块共6个8×8块）</p>
<ul>
<li><p>1帧：I-frame帧内帧：直接JPEG压缩（DCT+量化）；同时对压缩后的数据
作逆量化+逆DCT，存在帧缓存中（辅助 帧间帧P-frame 运动补偿）</p></li>
<li><p>2帧：运动补偿模块：输入：P-frame数据+帧缓存中数据；输出：运动矢量mv（moving
vector）</p></li>
<li><p>对于P-frame的每个宏块，根据mv得到帧缓存中画面的一个宏块，与原宏块作差值D，对D再进行DCT+量化，得到输出码流</p></li>
<li><p>更新帧缓存：对编码的差值D进行逆量化+逆DCT，与原本帧缓存中画面相加，得到新的帧缓存画面</p></li>
<li><p>3帧：继续下一帧。。。</p></li>
<li><p>量化阶回调：需要稳定的码流（每秒多少KB的数据）；则根据一定方法判断：</p>
<ul>
<li>剩余空间不足：则增大量化阶，之后的帧 减小 但质量差；</li>
<li>剩余空间较多：则减小量化阶，之后的帧 图像质量提高</li>
</ul></li>
</ul>
<p><strong>H.261 解码：</strong></p>
<ul>
<li>I-帧：直接解码输出，存入帧缓存；</li>
<li>P-帧：解码+帧缓存 =&gt; 输出，并更新帧缓存</li>
</ul>
<p><strong>H.261视频位流语法</strong>：</p>
<ul>
<li><p>宏块组（GOB）：</p>
<ul>
<li><p>将 3行 * 11列
个宏块，作为一个宏块组（176×48）；每个宏块组都有个编号</p></li>
<li><p>以宏块组为单位，进行网络传输（网络层，一个图像帧中
包含多个GOB）</p></li>
</ul></li>
<li><p>图像帧：</p>
<ul>
<li>图像层：
<ul>
<li>有同步头（17个1）</li>
<li>时间戳（几分几秒第几帧）</li>
<li>P/I-frame</li>
<li>各个GOB</li>
</ul></li>
<li>宏块组层：
<ul>
<li>有同步头</li>
<li>宏块组编号</li>
<li>宏块组的量化阶k（该组中的所有宏块的量化阶都 × k）（选用）</li>
<li>各个宏块（33个）</li>
</ul></li>
<li>宏块层：
<ul>
<li>没有同步头哦~因此出错，会限制在一个宏块组内</li>
<li>类型：可预测（则有运动矢量）/不可预测宏块</li>
<li>宏块公用量化阶（选用）</li>
<li>MVD：运动矢量（可预测）</li>
<li>CBP：（可预测）6个bit，每个bit对应后面的一个块；第ibit为1，代表第i块全0（表示与前一帧的块完全一样），则后面就不需要再编码第i块了</li>
<li>6个块（4Y+1Cb+1Cr，4：2：0）</li>
</ul></li>
<li>块层：（同JPEG）
<ul>
<li>DC：符号1（符号2的宽度）的霍夫曼编码，符号2（此块与上一块的差值）</li>
<li>交流系数：符号1（行程长度+符号2的宽度）的霍夫曼编码，符号2（遇到的第一个非零值）</li>
</ul></li>
</ul></li>
</ul>
<p>总览：<img src="F:\blog\source\_posts\figs\fig57.png" style="zoom:80%;" /></p>
<h4 id="h.263">H.263</h4>
<ul>
<li><p>增加了PB帧模式；</p></li>
<li><p>视频分辨率 扩充为5种；</p></li>
<li><p>宏块组划分：一行为一个宏块组</p></li>
</ul>
<p><strong>运动补偿：</strong></p>
<ul>
<li><p>当前宏块的运动矢量MV的编码：</p>
<ul>
<li>通过预测：<img src="F:\blog\source\_posts\figs\fig58.png" style="zoom:50%;" /></li>
<li>水平分量u，垂直分量v：<span class="math inline">\(u_p =
median(u_1,u_2,u_3)\)</span>，v同理
<ul>
<li>u，v初值：为<span class="math inline">\(u_p,v_p\)</span></li>
</ul></li>
<li>编码：对差值<span
class="math inline">\(u-u_p\)</span>（v同理）编码</li>
<li>特殊情况：MV左是边界，则MV1 =
（0，0）；MV上是边界，则MV2=MV3=MV1；MV右是边界，则MV3=（0，0）</li>
</ul></li>
<li><p>半像素运动补偿：</p>
<ul>
<li><p>半像素的亮度色度值，是通过预测获得的：</p></li>
<li><p>A b B：则b点亮度色度值为：(A+B<strong>+1</strong>) /
2（即A的和B的亮度/色度值 + 1 除以2）</p></li>
<li><p>落在A、B、C、D正中间，则为（A+B+C+D+2）/4</p></li>
</ul></li>
<li><p>不受限的运动矢量</p>
<ul>
<li>扩大运动矢量范围：允许运动矢量超出图像边界，<strong>超出部分用边界像素代替</strong></li>
</ul></li>
</ul>
<p>PB帧模式：I，P，B帧</p>
<ul>
<li>P帧：参考上一个I或P帧（同前）</li>
<li>B帧：同时参考前一个I/P 和 后一个I/P帧</li>
<li>匹配概率增大</li>
<li>问题：1.搜索更多，效率降低；2.编码顺序改变</li>
</ul>
<h4 id="mpeg系列">MPEG系列</h4>
<p>Moving Picture Experts
Group：主要用于娱乐方面的视频/音频（video/audio/data）编码标准</p>
<p>MPEG-1：将每秒200Mbps的NTSC（音视频信息）
压缩为大约1.5Mbps的（音视频复合）码流（其中视频大约占1.2Mbps）</p>
<p>MPEG-2：针对数字电视 和 高清视频 的编码标准</p>
<p>MPEG1,MPEG2：都是基于宏块的</p>
<p>MPEG-4：基于<strong>对象</strong>的
音视频编码标准（如视频中的人）；效果比1、2都要好很多</p>
<ul>
<li>H.264/265，也都算进了MPEG-4：主要不同是1.宏块再细分；2.还可以帧内差分（消除空间上的冗余）</li>
</ul>
<p>MPEG-7：多媒体内容描述接口；用来快速<strong>检索</strong>！</p>
<p>​ 各种多媒体信息，为其添加相应的 标准描述元数据（meta data）</p>
<p>MPEG-21：建立一个 多媒体应用框架；</p>
<h5 id="mpeg-1">MPEG-1</h5>
<ul>
<li><p>I, P, B,
D帧：（前仨同前所述）D帧，仅用每块的DC系数编码（快速预览时的小画面），单独进行编码和存储（仅MPEG-1用）</p></li>
<li><p>GOP（group of pictures）：视频画面序列
被分为一个个画面组；一般有10-15帧画面；必须有I帧，P</p>
<ul>
<li>画面的重新排序：<img src="F:\blog\source\_posts\figs\fig59.png" style="zoom: 67%;" /></li>
</ul></li>
<li><p>编码器结构：</p>
<ul>
<li><p>I帧、P帧：与前面的H261均相同</p></li>
<li><p>B帧：对每个宏块，分别在前和后两帧画面上找最相近块；若都找到了，则求平均，然后对差值进行JPEG编码</p></li>
<li><p>因此，可预测宏块
有3种类型：前向预测（P、B），后向预测（B），双向预测（B）</p></li>
<li><p>运动补偿 搜索策略：（额外的一种，老版本常用的）菱形搜索（DS）</p>
<ul>
<li>即从初始MV，计算菱形周围8个点（为mv）的sad 以及
当前中心点的sad，找到最小；</li>
<li>若是四周某点sad最小，则移动菱形中心到该点，重复上步；（关键在于，可以省去计算不少周围点（因为在之前已经计算过了））</li>
<li>直到中心最小，再计算一下紧挨着的4个点，即可<img src="F:\blog\source\_posts\figs\fig60.png" style="zoom: 50%;" /></li>
</ul></li>
</ul></li>
<li><p>缓冲器：（量化阶的调整）</p>
<ul>
<li><p>解码器端：以输入速率R
向Buffer（容量为B）中输入数据，每个1/P秒，从Buffer中取1帧解码好的画面</p></li>
<li><p>假设刚取完第n帧，Buffer中数据大小为Bn，第n+1帧数据大小为dn+1，则：</p></li>
<li><p>取第n+1帧不下溢：Bn+R/P &gt;= dn+1；</p></li>
<li><p>取第n+2帧前不上溢：(Bn+R/P) - dn+1 + R/P &lt;= B</p></li>
<li><p>则有：必须时刻满足：Bn+2R/P - B &lt;= dn+1 &lt;= Bn +
R/P；</p></li>
<li><p>编码器 根据这个约束不断进行量化阶回调？</p></li>
</ul></li>
<li><p>视频比特流的层次结构：</p>
<ul>
<li>序列层：分为若干GOP（图片组）单元；</li>
<li>GOP层：单元为一帧画面（Picture），且第一帧一定是I帧；GOP层支持<strong>随机存取</strong>！因为Picture是按时间排序，而B帧需要依赖后面的帧</li>
<li>图片层：单元为宏块片（Slice），slice可以在任意位置开始和结束，自定义</li>
<li>宏块片（slice）层：单元为宏块（该层对应H.261的宏块组层）</li>
<li>宏块层：单元为块</li>
<li>块层：DC系数，VLC run</li>
</ul></li>
<li><p>MPEG-1 vs. H.261:</p>
<ul>
<li><p>H.261只支持CIF（352x288）和QCIF（176x144）；MPEG支持SIF，以及一定限制下的自定义格式</p></li>
<li><p>量化：</p>
<ul>
<li>H.261没有量化表，64个系数的量化阶都相同（为2-64中的一个偶数）；</li>
<li>MPEG-1有量化表，区分Intra-code和Inter-code，前者各系数的量化阶都不同，后者则是64个系数统一一个较小的量化阶（较小因为运动补偿）；不区分亮度和色度分量的量化</li>
</ul></li>
<li><p>MPEG-1对解码端的缓冲要求更高（因为B帧）</p></li>
</ul></li>
<li><p>缺点：主要是分辨率 不够大；</p></li>
</ul>
<p><strong>MPEG-2</strong></p>
<ul>
<li>多规格：
<ul>
<li>支持各种分辨率最大可达16000×16000；</li>
<li>每秒可达60帧</li>
<li>支持 隔行、逐行 扫描</li>
</ul></li>
<li>分类分级：类（5），算法复杂度（高级 兼容
低级）；级（4），支持的分辨率
<ul>
<li>类：simple，main（最常用），SNR scalable，spatial scalable（前四种
色度格式：4：2：0），high（色度格式：4：2：2）
<ul>
<li>可伸缩性scalable思想：即
码流中包括：基础层+若干增强层；仅解码基础层，则是低分辨率
且低质的图像；同时还解码增强层，则叠加可获得 高分辨率/高清
等等的画面</li>
</ul></li>
<li>级：<img src="F:\blog\source\_posts\figs\fig61.png" style="zoom:67%;" /></li>
</ul></li>
</ul>
<p><strong>MPEG-4</strong></p>
<p>概述</p>
<ul>
<li>综合性：自然音视频对象 与 合成音视频对象
的集成（码流中可以同时包含自然/合成媒体对象，且合成也是用合成的方式编码）</li>
<li>交互性：选择播放，超链等（与<strong>码流</strong>交互！比如可以与视频中对象
进行交互（就像游戏））</li>
<li>高效率的压缩编码：与MPEG-2同等质量情况下 压缩至1/10</li>
</ul>
<p>可视对象编码</p>
<ul>
<li><p>第1代视频编码：单位是块（pixel），编码块的纹理texture
和运动motion（与MPEG-1/2同）</p>
<ul>
<li>不足：与人的视觉本质不同；同一对象的块运动应该差不多？不易控制场景中的不同对象</li>
</ul></li>
<li><p>第2代视频编码：基于object作编码（需要进行
对象的挖掘，将对象从视频画面中检测出）</p>
<ul>
<li><p>一段帧序列中，检测出若干个object，并以object为单位编码：包括对象的形状、纹理、运动</p></li>
<li><p>场景：由媒体对象 以层次方式
组合而成（树），叶节点是初级媒体对象：</p>
<ul>
<li>初级媒体对象：静止图像（固定的背景）；视频对象；音频对象；其他（文字/图形）</li>
<li>可自然媒体，也可合成媒体。体现出综合性！</li>
<li>以对象为单位，对象树为结构，则方便与视频流进行交互</li>
<li>BIFS：场景的二进制格式；用场景图表 表示：
<ul>
<li>节点：描述视听对象 及其属性；</li>
<li>图结构：描述各对象 空间和时间上的关系</li>
</ul></li>
</ul></li>
<li><p>VOP的编码：</p>
<ul>
<li><p>一个VOP 是一个VO在特定时刻的快照（形状、运动、纹理）</p>
<ul>
<li>若把整个矩形视频帧 当作一个VOP，则MPEG-4退化等同于MPEG-1/2</li>
</ul></li>
<li><p>每个VOP 定义在一个矩形边界框内（长宽 必须为
整数个宏块×宏块），且左+上边界，由VOP的左上决定，然后分宏块，如：<img src="F:\blog\source\_posts\figs\fig70.png" style="zoom:67%;" /></p></li>
<li><p>运动补偿：仍以16×16宏块为对象，但搜索范围
只在参考帧中对应VOP的范围内（也先要找到参考VOP的矩形边界框bounding
box）</p>
<ul>
<li><strong>填充</strong>步骤：对于边界宏块，VOP外的部分 需要进行填充
预处理（对参考VOP）
<ul>
<li>对边界宏块：先 水平重复填充；再
垂直重复填充（复制边界值，若在俩边界之间，则用平均值）（如图：该图是一个缩小的宏块）<img src="F:\blog\source\_posts\figs\fig71.png" style="zoom:67%;" /></li>
<li>对外部宏块：（边界框内VOP外，与边界宏块相邻的宏块）进行扩展填充
<ul>
<li>按照左、上、右、下的顺序，依次用相邻的边界宏块（or已经填充了的外部宏块）的边界像素值
进行扩展填充</li>
</ul></li>
</ul></li>
<li>计算SAD:
增加了一个MAP（p，q），仅当C(p,q)为目标VOP中的一个像素使，MAP(p，q)=1，否则为0（用来忽略掉VOP外部像素）<img src="F:\blog\source\_posts\figs\fig72.png" style="zoom:67%;" /></li>
</ul></li>
<li><p>纹理编码：即 灰度级/色度的变化 和 样式</p>
<ol type="1">
<li>基于DCT的纹理编码：边界外部分全填0</li>
<li>边界宏块的 形状自适应DCT：
<ul>
<li>1D DCT-N：1D
DCT的变体：DCT中固定了N=8，将时间域上的8个样本点，DCT为了8个频率域上的点（系数）；但这个N可以变为其他数</li>
<li>SA-DCT是一个2D
DCT：是两次DCT-N的叠加；应用于边界宏块的每一个8×8的块</li>
<li>对于8×8块：将VOP像素点
向上平移（俄罗斯方块）；按列作DCT-N，N为该列像素数；然后左平移，并按行作DCT-N；<strong>最后需要记录初始形状</strong>（二元掩码）
<ul>
<li>形状记录，和下面的同理</li>
</ul></li>
</ul></li>
</ol></li>
<li><p>形状编码：</p>
<ul>
<li>二元<span
class="math inline">\(\alpha\)</span>图：每一位的值，1/0表示该位置像素是/否在VOP内</li>
</ul>
<ol type="1">
<li>二元形状编码：将图分为16×16的块（二元<span
class="math inline">\(\alpha\)</span>块，BAB），只需要特殊处理
VOP边界的BAB（其他块 要么全0，要么全1）
<ol type="1">
<li>MMR 修订修改读算法：忽略</li>
<li>CAE 基于上下文的算术编码：
<ul>
<li>思想：边界BAB：对于当前像素，BAB内 该像素靠上临界的10个像素（的<span
class="math inline">\(\alpha\)</span>图）就构成了上下文，共1024种情况；可以用先验概率，构建一个概率表，表示这1024个上下文的出新频度。将当前这个像素
用其上下文的概率 替换（相当于1024个字母中的一个）；16×16
每个像素都这样，最后算术编码 =&gt; 32位浮点数</li>
<li>（左：I-帧边界BAB；右：P/B-帧（需
运动补偿的）边界BAB）<img src="F:\blog\source\_posts\figs\fig73.png" style="zoom:67%;" /></li>
<li>是无损的！</li>
</ul></li>
</ol></li>
</ol></li>
</ul></li>
</ul></li>
<li><p>MPEG-4视频流结构：5个层次，都<strong>支持随机访问</strong></p>
<ul>
<li>视觉对象序列（Video-object Sequence）：VS1, VS2, ...
<ul>
<li>VS 对应完整的MPEG-4视觉场景，可以包含 自然/合成对象</li>
<li>每个VS 由若干个视觉对象Visual Object组成</li>
</ul></li>
<li>视觉对象VO：每个对象由若干个 视频对象层VOL组成
<ul>
<li>VO对应场景中的一个对象or背景，可拥有任意形状</li>
</ul></li>
<li>视频对象层VOL：Video Object Layer
<ul>
<li>支持多层可扩展编码：一个VO 在可扩展编码下拥有多重VOL；非扩展编码下
拥有一个VOL（基础层）</li>
<li>由若干视频对象平面组GOV or 直接由若干 视频对象平面VOP组成</li>
</ul></li>
<li>视频对象组GOV：（可选层）由若干 视频对象平面VOP组成</li>
<li>视频对象平面VOP：描述：形状、运动、纹理</li>
</ul></li>
</ul>
<p>合成对象编码</p>
<ul>
<li><p>网格Mesh：多边形组成的二维平面区域的一部分，顶点为网格的节点；一般都是三角形网格</p>
<ul>
<li><p>主要性质：几何（坐标）；拓扑（哪几个点之间构成网格）</p></li>
<li><p>类型：（基本都是用Delaunay网格）</p>
<ul>
<li><p>均匀网格：<img src="F:\blog\source\_posts\figs\fig74.png" style="zoom:67%;" /></p></li>
<li><p>Delaunay网格：组成网格的三个点的外接圆内 没有第四个点 =&gt;
只要有了点阵，那么网格划分 就是确定唯一的！</p>
<ul>
<li>只需要记录 点的几何，而无需记录拓扑</li>
<li>如何记录几何？先记录最外围一圈的点，按x+y递增（同则y递增）顺序；内部点就任意顺序了
<ul>
<li>除第一个点坐标外，其余点都是记录差分！？</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>2D网格运动编码：</p>
<ul>
<li>网格点的运动，可由与之相关的2点的运动矢量 做预测编码（e=MV -
pred）；第一个MOP三角形运动确定后，所有与之公用1边的网格点也可以进行预测编码，不断重复该过程编码（BFS顺序）</li>
</ul></li>
</ul></li>
</ul>
<h2 id="ch.13-语音的压缩编码">Ch.13 语音的压缩编码</h2>
<p><strong>引言</strong></p>
<ul>
<li><p>可听声中，分 语音（300-3400Hz） 和
全频带声音（20-20kHz）</p></li>
<li><p>因此数字化时的 采样频率（不失真）：语音8kHz，全频带40kHz</p></li>
<li><p>基础知识：1.数字语音信号（如原始模拟信号对应的PCM信号），要输出还要再转会模拟信号（在<strong>时间上连续</strong>的信号，就是模拟信号！），但这样得到的是<strong>阶梯形信号</strong>！根据傅里叶分析理论，该信号包含无穷多的<strong>高频信号</strong>，因此为了消除额外引入的高频信号，将这个阶梯形信号
通过一个
<strong>低通滤波器</strong>，过滤掉所有超过<strong>原始模拟信号频率最大值</strong>的信号，如此就得到了平滑的模拟输出信号！</p></li>
<li><p>2.如果不对数字语音信号做压缩扩展，则每个采样点需要13位（12位+1符号位）描述（均匀量化）；但人耳对于高音的变化
和 低音的变化 响应程度是不同的，因此会对线性量化的PCM
再做压缩扩展（<span
class="math inline">\(\mu\)</span>率或A率扩展），得到对数量化信号，且每个采样点只需8位描述；</p></li>
<li><p>3.<span
class="math inline">\(\mu\)</span>率压扩公式：<img src="F:\blog\source\_posts\figs\fig62.png" style="zoom:50%;" /></p></li>
<li><p>A率压扩公式：<img src="F:\blog\source\_posts\figs\fig63.png" style="zoom: 50%;" /></p></li>
<li><p>但是直接使用这些公式不太现实（因为涉及浮点运算，很复杂），故实际应用时，采用的压扩算法：<img src="F:\blog\source\_posts\figs\fig64.png" style="zoom:50%;" /></p></li>
<li><p>其中符号位保留，红色丢弃</p></li>
</ul>
<p><strong>数字语音的波形编码</strong></p>
<ul>
<li>只考虑语音的波形状况
<ul>
<li>通用（无论是不是语音，都可以这样编码）；质量好</li>
<li>压缩效率不高</li>
</ul></li>
<li>三种波形编码方法
<ul>
<li>G.721，G.723。。。标准</li>
<li><span class="math inline">\(\mu\)</span>率编码的PCM（Pulse Code
Modulation脉冲编码调制）：即量化后的采样输出，不压缩，是<strong>无损声音</strong>
<ul>
<li>PCM主要解决：将线性量化的波形 转化为 <strong>对数量化</strong></li>
<li>PCM流程：输入：采样到的数字声音 =&gt;
带限/带通滤波（只保留300-3400kHz的波形）=&gt; 取样（每秒8k个样本）=&gt;
数模转换
（按13位（1符号+12幅值）做<strong>量化</strong>），得到13位的线性PCM
=&gt; 再进行压扩算法，得到每个样本8位的 PCM码流</li>
<li>PCM码率为：（每秒）8k×（每个样本）8b = 64kbps</li>
<li>PCM的应用：（是不压缩的，无损声音）通信：长途电话的传输；CD，DAT的全频带数字声音的存储</li>
</ul></li>
<li>ADPCM：（Adaptive Differential）自适应 差分 PCM
<ul>
<li>差分：通过已有样本，获得预测值；编码 预测值的差值</li>
<li>自适应：1.预测时的系数自适应；2.自适应改变量化阶（影响到差分编码的精度
和输出的码流）大小</li>
<li>差分编码时的量化阶：如图所示<img src="F:\blog\source\_posts\figs\fig65.png" style="zoom:67%;" /></li>
<li>其中的16
就是量化阶（可以自适应去调整，使得E较小时，采用较小的量化阶；大时再用大的）</li>
<li>ADPCM的码率 相较PCM 又降低了一半</li>
</ul></li>
<li>64kbps的声音子带编码：
<ul>
<li><strong>采样</strong>时 先按照频率 分若干的子带：
<ul>
<li>低频部分：采样率可以较低，而增加每个样本的比特数；</li>
<li>高频部分：采样率高，每个样本的比特数少些</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><strong>数字语音的参数编码</strong></p>
<ul>
<li><p>基于模型的 编码：将语音 抽象为 一段激励信号
经过<strong>滤波器</strong>过滤后得到的信号；</p>
<ul>
<li>因此只需要编码 激励信号+滤波器参数；</li>
<li>只能处理语音、质量差；但安全</li>
<li>编码时：从语音波形信号中
提取生成该语音的<strong>参数</strong>；</li>
<li>解码时：根据<strong>语音生成模型</strong>，使用这些<strong>参数</strong>来合成出
原始语音</li>
</ul></li>
<li><p>语音生成过程：</p>
<ul>
<li>假设：1.语音生成模型，每20ms左右才改变一次（期间是稳定的）</li>
<li>2类语音：浊音（激励信号为 周期的脉冲信号）；清音（激励信号为
随机噪声）</li>
<li>故一段语音，可分为：以20ms为一单位的，一段段激励信号（对应浊音、清音）；以20ms为一帧
进行编码</li>
</ul></li>
<li><p>语音的参数编码（LPC分析：Linear Predictive Coding）</p>
<ul>
<li><p>LPC模型的参数A = (a1,a2~a10, G, V/UV,
T)：a1~a10为声道参数？；G增益参数（即激励信号的大小）；V浊音/UV清音；若是V
还有T 基音周期；参数A大约每10~30ms变化一次</p></li>
<li><p>假设语音信号取样频率为8kHz，每秒分成50帧（20ms一帧），则一帧对应160个采样点；每帧信号近似满足同一模型（用同一组参数描述）：<img src="F:\blog\source\_posts\figs\fig66.png" style="zoom:67%;" /></p></li>
<li><p>如何求出每一帧的 各参数呢？a1~a10
需要求解一个线性约束方程？</p></li>
<li><p>码率超小哦~</p></li>
</ul></li>
</ul>
<p><strong>数字语音的混合编码</strong></p>
<ul>
<li>通过提高<strong>激励信号</strong>的质量 来改进参数编码；+编码时
根据当前激励信号+参数 合成的语音信号 与
原语音信号对比，不断调整激励信号</li>
<li>最佳激励信号u（n）的生成方法：
<ul>
<li>多脉冲线性预测编码MPLPC：
<ul>
<li>每帧仍20ms；清音 和 浊音 的激励信号都由k个脉冲组成，每个脉冲的幅度
和 位置 待定；即对每一帧，都要去确定这k个脉冲的位置和大小</li>
<li>数据量太大</li>
</ul></li>
<li><strong>等间隔</strong>脉冲激励RPE：
<ul>
<li>每5ms一组激励信号，有13个脉冲，且<strong>间隔相等</strong>，只需确定脉冲的大小</li>
</ul></li>
<li>码激励CELP：
<ul>
<li>将有限数量的激励信号
存储在存储器中（称为码本）；通过在码本中选择最优的激励信号</li>
</ul></li>
</ul></li>
</ul>
<h2 id="ch.14-mpeg声音">Ch.14 MPEG声音</h2>
<p>（全频带声音）与语音的主要区别：</p>
<ol type="1">
<li>采样率高（一般44.1kHz）</li>
<li>每个样本要16bit；2声道；故数据量远高于语音编码</li>
<li>对编码质量要求更高</li>
</ol>
<p><strong>听觉系统的感知特性</strong></p>
<ul>
<li><p>响度：描述声音强弱，通常用<strong>声强级</strong>来描述；</p>
<ul>
<li>声强 单位：<span class="math inline">\(I_0 =
10^{-12}\)</span>W/<span class="math inline">\(m^2\)</span>
<ul>
<li>意义：频率为1000Hz的声波 能被人听见的最弱声强</li>
</ul></li>
<li>声强级L：<span class="math inline">\(L_1 =
\lg\frac{I}{I_0}\)</span>贝尔（Bel）
<ul>
<li><span class="math inline">\(L_1 =
10(\lg\frac{I}{I_0})\)</span>分贝（dB）</li>
</ul></li>
<li>听觉阈电平：该频率的声音，被人听到的 最低电平（声强？）
<ul>
<li>一个人的听阈 随 频率变化而变化；一般对2k~5kHz声音最明显；</li>
<li>等响度级 曲线：尽管两个频率的声音的<strong>客观声强级</strong>
可能不同，但对于人来说 感觉上是一样的</li>
</ul></li>
</ul></li>
<li><p>听觉掩蔽特性：</p>
<ul>
<li><p>一种频率的声音 可能会阻碍听到
另一种频率的声音；前者：掩蔽声音；后者：被掩蔽声音</p></li>
<li><p>频率掩蔽：（根据频率和声强 的掩蔽效应）</p>
<ul>
<li><p>同频率声音：强纯音（仅一个频率存在） 掩蔽弱纯音</p></li>
<li><p>不同频率：弱纯音的频率 离 强纯音越近，就越容易被掩蔽</p></li>
<li><p>纯音的掩蔽效应曲线：（曲线下的对应声强和频率的纯音会被掩蔽
听不到）<img src="F:\blog\source\_posts\figs\fig67.png" style="zoom:67%;" /></p></li>
<li><p>1.低频纯音，对高频纯音的掩蔽效应更明显；2.掩蔽效应的作用范围和大小，与声强
及 频率有关：频率高，声强强 则掩蔽效应越大</p></li>
</ul></li>
<li><p>时域掩蔽：在时间上相邻的声音
相互掩蔽；主要因为人脑处理信息需要时间</p>
<ul>
<li>基于频率掩蔽，被掩蔽 和 掩蔽声音同时存在 =&gt;
掩蔽声音突然停止，仍需要一段时间 才能听到被掩蔽声音（滞后掩蔽）；</li>
<li>某一高分贝声音在某一时刻突然出现，则会提前掩蔽一些其他频率的
低分贝声音（超前掩蔽）</li>
<li>如图：<img src="F:\blog\source\_posts\figs\fig68.png" style="zoom:67%;" /></li>
</ul></li>
<li><p>用处：判断噪音 对 声音信号的影响有多大（如果引入的噪音
可以被正常声音信号所掩蔽，则ok）</p></li>
</ul></li>
<li><p>临界频带：（压扩算法的想法？根据人耳的感知特性，将声音频率
非均匀的划分频带）</p>
<ul>
<li><p>非线性的25个频带；同一频带中的声音（对人耳而言）相同</p></li>
<li><p>在临界频带基础上，画掩蔽效应曲线</p></li>
</ul></li>
</ul>
<p><strong>MPEG-1 audio</strong></p>
<p>目标：将传输速率为1.4Mbps（咋算的？44.1k x 16b x 2声道）的CD音质声音
压缩为0.3Mbps</p>
<p>MPEG-1音频的基本性能：</p>
<ul>
<li><p>输入：采样频率32k,44.1k,or
48kHz；量化精度16bit；全频带声音（20-20kHz）</p></li>
<li><p>输出：码率：32k~384kHz（离散的）</p></li>
<li><p>提供三个独立的压缩层次：1、2、3（MP3 就是用layer3）；一个层次
代表一个 音频编码标准？高层 都可以兼容低层</p>
<ul>
<li>layer1：只用了频率掩蔽</li>
</ul></li>
<li><p>支持4种模式：1.单声道；2.双声道；（左右声道信号
编码在同一比特流中）3.立体声；（左右声道信号
分别编码在不同比特流？）4.联合立体声（降低了输出比特流的码率）</p></li>
<li><p>支持在数据流中 添加额外的信息</p></li>
</ul>
<p>MPEG-1音频编码：（<strong>layer1</strong>）</p>
<ul>
<li><p>原理：</p>
<ul>
<li><p>音频信号会分割为32个子频带，每个子频带
是<strong>等宽</strong>的，从最低频率，到最高映射频率</p></li>
<li><p>利用掩蔽特性：</p></li>
</ul></li>
<li><p>编码器：</p>
<ul>
<li>输入：数字声音（以帧
为单位进行编码，<strong>一帧包含连续的384个样本</strong>）；</li>
<li>时间-频率变换组件：将原本的384个样本，转化为12组样本集合，每组包含32个样本（12x32=384）
<ul>
<li>划分成了32个子频带，在这32个子频带
分别有12个样本（<strong>通过一个子带滤波器</strong>；总时间都是原384个样本的时间）；即相当于是32个PCM样本</li>
</ul></li>
<li>心理声学模型：使用频率掩蔽特性，计算这32个子频带的每个，对其余频带的掩蔽值
<ul>
<li><strong>信掩比：</strong>SMR ，每一个频段中 短期信号的能量（即该频带
对应的12个样本信号 对应的能量？） 与 （该频带的）最小子带遮掩阈值
的比值（与 SNR 单位均是dB，因为都是声音强度的比值，且分子都相同）</li>
</ul></li>
<li>量化，编码：根据信掩比，为每组样本进行<strong>比特分配</strong>（0~15bit），指出每组样本分别使用几位表示</li>
<li>将量化编码后的样本数据 封装成一帧数据，输出到码流</li>
</ul></li>
<li><p>量化器的比特分配算法：</p>
<ul>
<li>确定了输出的码率（会指定好，最高384kbps，离散的几个值），则每一帧可分配的比特数目就确定了；</li>
<li>假设 输出码率为p，则每一帧可分配比特数A = <span
class="math inline">\(\frac{384}{44100}\times p/2\)</span>(声道) -
文件头/额外信息等消耗的bit数</li>
<li>bit分配方法：在不超过总数A的前提下，使这一帧的 总掩蔽与噪声
之比<span class="math inline">\((\Sigma\)</span>
MNR)最小（<strong>？？</strong>）
<ul>
<li>掩蔽与噪声比 小 ：则噪声越明显，越容易被听见</li>
<li>每个自带的MNR = SNR - SMR（量化器信噪比（由量化位数决定） -
子带的信掩比（心理声学模型中确定，不会变了））
<ul>
<li>噪声：（信号中的随机扰动）
量化噪声，由量化误差引入的：如原信号140，量化后为150，则引入了量化误差
和 量化噪声</li>
<li>1.为每个频带的每个样本 分配2bit；（已经用掉了768个bit（对于））</li>
<li>2.找到MNR最小的子带，给12个样本分配一个比特（降低量化误差，提高SNR）</li>
<li>3.计算所有量化器输出样本
比特总数，并与A比较，若不超过，则增加量化器位数</li>
<li>4.重复步骤2，3；直到总数接近A</li>
</ul></li>
</ul></li>
</ul></li>
<li><p>MPEG-1音频（层1）的帧结构：（没有文件头，就是一帧一帧数据组成）</p>
<ul>
<li>同步头32bit：+一些属性信息
<ul>
<li><img src="F:\blog\source\_posts\figs\fig69.png" style="zoom: 50%;" /></li>
<li>位速率索引：共16种不同的输出码率32k，64k，96k，128k，448kbps
。。。</li>
<li>采样频率：决定每秒播放多少个样本！</li>
</ul></li>
<li>CRC：循环冗余码</li>
<li>32个子带：（每个子带的结构为）
<ul>
<li>比特分配4bit：描述分配给该子带的量化比特数目（因此最多分配15个bit）</li>
<li>比例因子6bit：量化比例因子</li>
<li>子带样本：12个样本 × nbit（分配的比特长度）</li>
</ul></li>
<li>附加数据：（因为每一帧的总长度固定，指定了输出码率）固末尾补零/or一些其他信息（专辑/歌手信息）</li>
</ul></li>
<li><p><strong>layer2</strong>的改进：</p>
<ul>
<li>1帧包含1152个样本（3 ×
384）；仍是32个子频带，每个子频带36个样本</li>
<li>心理声学模型：不仅使用频率掩蔽，还用了时域掩蔽</li>
</ul></li>
<li><p><strong>layer3</strong>的改进：</p>
<ul>
<li>最主要的改进：时域-频率转换部件：转换为
32个<strong>临界频带</strong></li>
</ul></li>
</ul>
<p><strong>MPEG-2 audio</strong></p>
<p>MPEG-2 Audio：延用扩充MPEG-1</p>
<p>MPEG-2 AAC：与Audio标准 完全不相关！</p>
<ul>
<li>取样频率：从8k~96kHz（人耳最高就听到20kHz。。）</li>
<li>编码器的分类分级：根据自身设备，选择解码适合的码流</li>
</ul>
<p><strong>MPEG-4 audio</strong></p>
<p>自然音频信号 和 合成音频信号 的编码：<strong>统一</strong></p>
<p><strong>Dolby AC-3</strong>（全频带声音的其他编码）</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CS/" rel="tag"># CS</a>
              <a href="/tags/Lecture-notes/" rel="tag"># Lecture notes</a>
              <a href="/tags/Multimedia/" rel="tag"># Multimedia</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/02/15/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/" rel="prev" title="编译原理">
      <i class="fa fa-chevron-left"></i> 编译原理
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/02/17/OOD/" rel="next" title="OOD">
      OOD <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#intro"><span class="nav-number">1.</span> <span class="nav-text">Intro</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E7%BC%96%E7%A0%81"><span class="nav-number">2.</span> <span class="nav-text">文本编码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80"><span class="nav-number">3.</span> <span class="nav-text">数字图像基础</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E5%AD%97%E8%A7%86%E9%A2%91"><span class="nav-number">4.</span> <span class="nav-text">数字视频</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A3%B0%E9%9F%B3"><span class="nav-number">5.</span> <span class="nav-text">声音</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A3%B0%E9%9F%B3%E7%9A%84%E6%95%B0%E5%AD%97%E5%8C%96"><span class="nav-number">5.0.1.</span> <span class="nav-text">声音的数字化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%88%E6%88%90%E8%AF%AD%E9%9F%B3"><span class="nav-number">5.0.2.</span> <span class="nav-text">合成语音</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%90%88%E6%88%90%E9%9F%B3%E4%B9%90"><span class="nav-number">5.0.3.</span> <span class="nav-text">合成音乐</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">压缩算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%97%A0%E6%8D%9F%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="nav-number">6.0.1.</span> <span class="nav-text">无损压缩算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%89%E6%8D%9F%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95"><span class="nav-number">6.0.2.</span> <span class="nav-text">有损压缩算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#jpeg%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9%E6%A0%87%E5%87%86"><span class="nav-number">7.</span> <span class="nav-text">JPEG（图像压缩标准）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#jpeg%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9%E7%9A%84%E4%B8%BB%E8%A6%81%E6%AD%A5%E9%AA%A4"><span class="nav-number">7.0.1.</span> <span class="nav-text">JPEG图像压缩的主要步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%BC%96%E7%A0%81%E6%A8%A1%E5%BC%8F"><span class="nav-number">7.0.2.</span> <span class="nav-text">编码模式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#jpeg2000"><span class="nav-number">7.0.3.</span> <span class="nav-text">JPEG2000</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ch10.-%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E5%9F%BA%E7%A1%80"><span class="nav-number">8.</span> <span class="nav-text">Ch10. 视频压缩基础</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%96%B9%E6%B3%95"><span class="nav-number">8.0.1.</span> <span class="nav-text">视频压缩的基本方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#h.261"><span class="nav-number">8.0.2.</span> <span class="nav-text">H.261</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#h.263"><span class="nav-number">8.0.3.</span> <span class="nav-text">H.263</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#mpeg%E7%B3%BB%E5%88%97"><span class="nav-number">8.0.4.</span> <span class="nav-text">MPEG系列</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#mpeg-1"><span class="nav-number">8.0.4.1.</span> <span class="nav-text">MPEG-1</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ch.13-%E8%AF%AD%E9%9F%B3%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81"><span class="nav-number">9.</span> <span class="nav-text">Ch.13 语音的压缩编码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ch.14-mpeg%E5%A3%B0%E9%9F%B3"><span class="nav-number">10.</span> <span class="nav-text">Ch.14 MPEG声音</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zeyu Huang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zeyu Huang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
